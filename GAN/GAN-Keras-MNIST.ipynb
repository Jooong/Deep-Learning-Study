{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본래 목적은 아래 링크에서 작성한 MNIST GAN - Pytorch version을 Keras로 직접 옮겨보는 것이었습니다.\n",
    "\n",
    "https://github.com/Jooong/Deep-Learning-Study/blob/master/2017-07-29-GAN-tutorial-2-MNIST.markdown\n",
    "\n",
    "하지만 주먹구구식으로 코드를 작성한 결과,아래의 이미지에서 더이상 학습이 되지 않는 현상이 발생했습니다..\n",
    "<img src = \"https://scontent-hkg3-2.xx.fbcdn.net/v/t1.0-9/20479575_1545344795530358_5123431362607095007_n.jpg?oh=8f81a0bec8575f612918afa1239d88a4&oe=5A017A15\"></img>\n",
    "\n",
    "문제를 해결하기위해 갖은 노력을 해보았지만 in vain...\n",
    "\n",
    "결국 \"참고\"만 하려던 아래 링크의 코드를 거의 갖다 쓰다시피 하게 되었습니다..\n",
    "\n",
    "https://github.com/Zackory/Keras-MNIST-GAN/blob/master/mnist_gan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some values & load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dim of noise vector == 100 -> most of GAN implementations do so.\n",
    "noiseDim = 100\n",
    "examples = 16\n",
    "\n",
    "# set sample noise to keep track of how well Generator is trained\n",
    "sample_noise = np.random.normal(0, 1, size=[examples, noiseDim])\n",
    "\n",
    "\n",
    "\n",
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "np.random.shuffle(X_train)\n",
    "\n",
    "# make mini batches\n",
    "BATCH_SIZE = 100\n",
    "NUM_BATCH = X_train.shape[0] // BATCH_SIZE\n",
    "X_batches = np.array([X_train[i:i+BATCH_SIZE] for i in range(NUM_BATCH)])\n",
    "\n",
    "# List for tracking losses\n",
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Build Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "# Layer1\n",
    "generator.add(Dense(256, input_dim=noiseDim, init=initializers.RandomUniform(minval=-1, maxval=1, seed=None)))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Layer2\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Layer3\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Layer4\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Build Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "# Layer1\n",
    "discriminator.add(Dense(1024, input_dim=784, init=initializers.RandomUniform(minval=-1, maxval=1, seed=None)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "\n",
    "# Layer2\n",
    "discriminator.add(Dense(512))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "\n",
    "# Layer3\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "\n",
    "# Layer4\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Combine D & G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False    # disable training of discriminator while training Generator\n",
    "ganInput = Input(shape=(noiseDim,)) # Init Keras Tensor\n",
    "x = generator(ganInput)             # Generate Fake Images\n",
    "ganOutput = discriminator(x)        # Test Discriminator with the Fake Images\n",
    "gan = Model(input=ganInput, output=ganOutput)  # random noise -> GAN -> probability vector\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss from each batch\n",
    "def plotLoss(epoch):\n",
    "    df = pd.DataFrame([dLosses,gLosses]).T.rename(columns={0:\"d_loss\",1:\"g_loss\"})\n",
    "    df.iplot(title=\"Tracking Losses of Discriminator and Generator\",\n",
    "             xTitle=\"Epoch\",yTitle=\"Loss\",\n",
    "             filename='results/gan_loss_epoch_%d.png' % epoch)\n",
    "    \n",
    "    \n",
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, noise, examples=16, dim=(4, 4), figsize=(10, 10)):\n",
    "\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/gan_generated_image_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epochs=200, batchSize=100):\n",
    "    batchCount = X_train.shape[0] // batchSize\n",
    "    print( 'Epochs:', epochs)\n",
    "    print( 'Batch size:', batchSize)\n",
    "    print( 'Batches per epoch:', batchCount)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print( '-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for i in tqdm_notebook(range(len(X_batches))):\n",
    "            \n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            imageBatch = X_batches[i]\n",
    "            \n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            \n",
    "            # input Matrix for Discriminator\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            yLabel = np.zeros(2*batchSize)\n",
    "            \n",
    "            # Labels for real data == 1\n",
    "            yLabel[:batchSize] = 1\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yLabel)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "\n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "\n",
    "        \n",
    "        plotGeneratedImages(e, sample_noise)\n",
    "\n",
    "\n",
    "        # Plot losses from every epoch\n",
    "        plotLoss(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(200, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch v.s. Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델을 Class로 구현해야한다.(Pytorch 자체가 그렇게 강제한다)\n",
    "    * init에서 레이어 빌딩 등 모델에 대한 그래프를 그려야 하고\n",
    "    * forward()메소드를 구현하여 모델의 output을 명시해야한다.\n",
    "    * 레이어를 쌓는 방법은 간단하다. Sequential() 객체 안에 레이어를 인자로 순서대로 넣어주면 된다.\n",
    "    \n",
    "    \n",
    "* Backpropagation과 parameter update를 명시해야 한다.\n",
    "    * model 변수에 .back()과 .step() 메소드를 사용하면 된다.\n",
    "    * GAN처럼 서로 다른 뉴럴 네트워크가 한 모델 안에 존재하는 경우, 각각의 네트워크를 따로 학습시키기가 쉽다.\n",
    "        * back()과 step()을 명시하므로써 뭔가 내가 학습과정을 더 쉽게 control할 수 있는 것 같다.\n",
    "        * 결정적으로 Pytorch가 Keras보다 코드를 짜다고 쉽게 느낀 부분은, D와 G 두 네트워크를 별개로 학습시킬 수 있었기 때문이다.\n",
    "        * Keras는 generator와 discriminator를 stack한 GAN 모델 자체를 명시해야 하는데, 이 부분이 그렇게 직관적으로 이해되지는 않았다.\n",
    "        \n",
    "\n",
    "* Mini Batch 구현을 따로 해주지 않아도 된다.\n",
    "    * DataLoader()를 사용하면 된다.\n",
    "    * 물론, 이미지가 아닌 음성이나 다른 형식의 데이터를 사용한다면, DataLoader를 상속받아 새로 구현해주어야 한다.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델을 Model() 혹은 Sequential()이라는 객체를 통해 구현할 수 있다.\n",
    "    * 보통 Sequential() 객체에 layer를 쌓은 후 이 모델을 반환하는 함수를 많이 쓰는 것 같다.\n",
    "    * 하지만 여기서는 Model을 그냥 전역변수를 만들어서 쭉 코딩하는 형태를 취했다.\n",
    "    * layer를 쌓은 뒤에는 컴파일을 해주어야 한다. 컴파일할 때 optimizer와 loss를 명시한다.\n",
    "    \n",
    "    \n",
    "* 학습 시 train_on_batch() 메소드를 사용하면 된다.\n",
    "    * 이 외에도 .predict() / .fit() 등 다른 ML 라이브러리(TF / sklearn)들의 객체와 유사하다.\n",
    "    * trainable이라는 멤버변수를 통해 모델의 일부를 학습시키지 않을 수도 있다.\n",
    "        * Generator를 학습시키는 과정에서 사용되었다.\n",
    "        \n",
    "        \n",
    "* Discriminator는 Discriminaotor 단독적으로 학습시키고, Generator는 얘를 직접 학습시키는 게 아니라 상위 모델인 GAN을 학습시키는 형태다.\n",
    "    * 위에서 말했듯, 이 부분이 좀 헷갈렸다. \n",
    "    \n",
    "    \n",
    "* Pytorch를 먼저 쓰고 Keras를 쓰니깐 괜히 맘에 안드는 부분이 있는 것 같다.\n",
    "    * 하지만 뭐가 됐든 TensorFlow보단 편한 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아무래도 원래 있던 코드를 내가 임의로 변경하다보니 결과물이 이상하게 나온 것 같다.\n",
    "\n",
    "우선 g_loss가 수렴하지 않는다. 학습이 진행됨에 따라 점차 증가해야할 d_loss는 감소 수렴한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scontent-hkg3-2.xx.fbcdn.net/v/t1.0-9/20431352_1545641782167326_1401401417222284106_n.jpg?oh=e8f656a23c1ca509214782c5aabe53f4&oe=5A2F489C\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "또한, 결과물로 나오는 fake 이미지가 모두 1만 표현한다. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"https://scontent-hkg3-2.xx.fbcdn.net/v/t1.0-9/20429929_1545641018834069_1261116936006292570_n.jpg?oh=612bc7fdd7f9b2a8da89541457cd8555&oe=5A05AADE\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조만간 이 문제사항에 대해 살펴본 후, ver2를 업로드할 예정이다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
